---
title: "Assignment 5: kNN Regression and Classification"
author: "Maria Sanchez"
date: "October 8, 2024"
format: html
editor: source
self-contained: true
toc: true
toc-expand: true
toc-depth: 3
---


```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_knit$set(root.dir = '/Users/mariasanchez/Documents/QTM6300')
```

# Context

Let’s take a look at the data located in UniversalBank.csv. Each row represents a customer at small but rapidly growing bank. The columns measure all sorts of customer characteristics, ranging from their demographic information (e.g., Age, Family) to whether they currently have various accounts open with the bank (e.g., Securities Account, CD Account). For a complete description of the fields, consult the data page on Canvas.

There are two characteristics of customers that would be used for the company to predict.

Task 1. First, the bank would like to predict a customer's Mortgage amount (the "Mortgage" variable.) The bank would like a model to make an educated prediction on income so that they may target customers with appropriate marketing.

Task 2. Secondly, the bank is aggressively trying to convert customers from depositors into borrowers through its personal loan program. The column **Personal Loan** shows whether each customer responded to a direct marketing campaign related to this program. The marketing team is now trying to understand what types of customers responds to new personal loans marketing. If they can establish reasonably strong predictive power, they will deploy the model more widely across their customer base to identify promising leads and a more nuanced target market.


# Task 1: Predicting Mortgage Amount

## Question 1

Do the following:

* Import the data as "bank"

* Remove all non-numeric variables from the data frame. Anything that feels more categorical than numeric should be nulled out. This is because in kNN, we cannot use any variable as predictors when we have difficulty calculating the distance. I would also say that anything that doesn't make sense as a numeric value (like Zip Code), or something that should not be predictive (like ID) of the dependent variable, should also be nulled out.


```{r}
"bank" <- read.csv('UniversalBank.csv')
bank$ID <- NULL
bank$ZIP.Code <- NULL
bank$Education <- NULL
bank$Personal.Loan <- NULL
bank$Securities.Account <- NULL
bank$CD.Account <- NULL
bank$Online <- NULL
bank$CreditCard <- NULL

```


## Question 2

* Set a seed of 72 and partition a training set with 55% of the data.

```{r}
set.seed(72)
N <- nrow(bank)
trainingSize <- round(N*0.55)
trainingCases <- sample(N, trainingSize)
training <- bank[trainingCases, ]
test <- bank[-trainingCases, ]
```


## Question 3

* Build a kNN regression model using standardized features ("indepedent variables") to predict Mortgage in R. Set it up so that you are using the four closest neighbors for the predictions.

```{r}
library(caret)
model <- knnreg(Mortgage ~ ., data=training, k=4, preProcess=c("center","scale"))

```

## Question 4

Apply the model to the test data frame. Then, store the predicted values in both the object "predictions" and within the test data frame so you can clearly see what the predictions are when you view the data frame.

```{r}
predictions <- predict(model, test)
test$predictions <- predict(model, test)
#View(test)
```

## Question 5
Evaluate the model. Calculate the MAPE and the RMSE. What are they? Interpret each of the them.

```{r}
observations <- test$Mortgage
errors <- observations - predictions
mape <- mean(abs(observations-predictions)/observations)
mape

rmse <- sqrt(mean((observations-predictions)^2))
rmse
```

## Question 6
In one sentence, interpret the MAPE from the last question using the appropriate units. (Note: It is possible that you received a MAPE that is NaN or Inf, or basically incalculable. If you do, I will provide extra credit IF you can *clearly* explain why it is incalculable. Try to think about the MAPE equation and also take a look at the data.))

Answer: The MAPE is NaN because the Mortgage values in the dataset include zero values, which leads to division by zero in the MAPE calculation and results in undefined values.

## Question 7
In one sentence, interpret the RMSE from Question 6 using the appropriate units.

Answer: The RMSE is about 110.264, meaning that, on average, the model’s predictions for the mortgage amount are off by approximately $110.264

## Question 8
Calculate the benchmark MAPE and RMSE when using the mean as the prediction. Is your model useful? Why or why not?

Answer: No, it's not useful because the RMSE of the kNN model (110.264) is higher than the benchmark RMSE (101.647), meaning that the model’s predictions are less accurate. 

```{r}
errors_bench <- observations - mean(training$Mortgage)
mape_bench <- mean(abs(errors_bench)/observations)
mape_bench
rmse_bench <- sqrt(mean(errors_bench^2))
rmse_bench
```


# Task 2: Predicting Personal Loan Offer Acceptance

## Question 9

We will now turn our attention to creating a kNN Classification model to predict whether a customer would accept a personal loan offer. Make sure your code is in the following order:

* First, let's clear the global environment to make sure we don't confuse our previous data and model with this one.

* Second, Import the data as "bank" once again.

* Third, remove all non-numeric variables from the data frame except the target variable. Anything that feels more categorical than numeric should be nulled out. This is because in kNN, we cannot use any variable as predictors when we have difficulty calculating the distance. I would also say that anything that doesn't make sense as a numeric value (like Zip Code), or something that should not be predictive (like ID) of the dependent variable, should also be nulled out.

* Fourth, convert the target variable to a factor

* Fifth, standardize all the numeric predictors.

* Sixth, set a seed of 72 and partition a training set with 55% of the data once again.

```{r}
rm(list = ls())
"bank" <- read.csv('UniversalBank.csv')
bank$ID <- NULL
bank$ZIP.Code <- NULL
bank$Education <- NULL
bank$Securities.Account <- NULL
bank$CD.Account <- NULL
bank$Online <- NULL
bank$CreditCard <- NULL

bank$Personal.Loan <- as.factor(bank$Personal.Loan)
standardizer <- preProcess(bank, c("center","scale"))
bank <- predict(standardizer, bank)

set.seed(72)
N <- nrow(bank)
trainingSize <- round(N*0.55)
trainingCases <- sample(N, trainingSize)
training <- bank[trainingCases, ]
test <- bank[-trainingCases, ]

```

## Question 10

* Train the kNN classification model using all available numeric inputs, using the four closest neighbors to make a prediction. Make sure to standardize your predictors.

```{r}
model <- knn3(Personal.Loan ~ ., data=training, k=4)
predictions <- predict(model, test, type="class")
test$predictions <- predict(model, test, type="class")

```


## Question 11

Create the confusion matrix to see the errors. 

```{r}
observations <- test$Personal.Loan
table(predictions, observations)

```

## Question 12

How many total predictions did the model get correct? (Not percentage)

Answer: The model got correct 2081 predictions.

```{r}
table(predictions, observations)
1989+92
```


## Question 13

How many total predictions did the model get incorrect? (Not percentage)

Answer: The model got incorrect 169 predictions.

```{r}
table(predictions, observations)
120+49
```


## Question 14

Manually calculate the error rate (according to numbers you received in the confusion matrix. Show calculations using R as a calculator.

Answer: 

```{r}
(49+120)/(1989+120+49+92)
```



## Question 15

Now, Calculate the error rate using R code. Make sure your manual calculation is correct.

```{r}
error_rate <- sum(predictions != observations)/nrow(test)

```


## Question 16

Calculate the benchmark error rate. You can do this using code. (NOte that, however- for practice- you should also be able to get the same benchmark error rate using the confusion matrix!)

Answer:

```{r}
source('BabsonAnalytics.R') 
error_bench <- benchmarkErrorRate(training$Personal.Loan, test$Personal.Loan)
error_bench
```


## Question 17

Is your error rate for the model better than the benchmark?

Answer: Yes, the error rate is better than the benchmark because it's lower.




## Question 18

Calculate the sensitivity. You can use either code or the confusion matrix to do so manually.

Answer:


```{r}
92/(120+92)
```


## Question 19

Calculate the specificity. You can use either code or the confusion matrix to do so manually.

Answer:

```{r}
(1989)/(1989+49)

```

